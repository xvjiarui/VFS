<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
        content="Rethinking Self-Supervised Correspondence Learning: A Video Frame-level Similarity Perspective">
    <meta name="author" content="Jiarui Xu, Xiaolong Wang">

    <title>
        Rethinking Self-Supervised Correspondence Learning: A Video Frame-level Similarity Perspective
    </title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
        integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <link rel="icon" href="fig/ucsd.png" type="image/gif">
</head>

<body>
    <div class="jumbotron jumbotron-fluid">
        <div class="container"></div>
        <h2>Rethinking Self-Supervised Correspondence Learning:<br>A Video Frame-level Similarity Perspective</h2>
        <h3>ICCV 2021 (Oral)</h3>
        <hr>
        <p class="authors">
            <a href="https://jerryxu.net/">Jiarui Xu</a>,&emsp;
            <a href="https://xiaolonw.github.io/">Xiaolong Wang</a>
        </p>
        <div class="btn-group" role="group" aria-label="Top menu">
            <a class="btn btn-primary" href="https://arxiv.org/pdf/2103.17263">Paper</a>
        </div>
        <div class="btn-group" role="group" aria-label="Top menu">
            <a class="btn btn-primary" href="https://github.com/xvjiarui/VFS/">Code</a>
        </div>
        <div class="btn-group" role="group" aria-label="Top menu">
            <a class="btn btn-primary" href="vfs_oral_slide.pdf">Slide</a>
        </div>
    </div>

    <div class="container">
        <div class="section">

            <div class="row align-items-center" onmouseout="vfs_stop()" onmouseover="vfs_start()">
                <!-- <div class="row align-items-center" onmouseout="vfs_play()" onmouseover="vfs_pause()"> -->
                <!-- <div class="row align-items-center"> -->
                <div class="col-sm-12 center">
                    <!-- <img src="./fig/teaser.png" style="width:100%"></img> -->
                    <div class="one col-sm-12" style="padding-left: 0px; padding-right: 0px;">
                        <div class="two col-sm-12" style="padding-left: 0px; padding-right: 0px;" id='vfs_image'">
                            <video id=" teaser_video" width=100% height=100% muted autoplay loop>
                            <source src="./fig/vfs_gif.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                            </video></div>
                        <img src='./fig/vfs_gif.png' width="100%">
                    </div>
                    <script type="text/javascript">
                        function vfs_start() {
                            document.getElementById('vfs_image').style.opacity = "1";
                        }

                        function vfs_stop() {
                            // document.getElementById('vfs_image').style.opacity = "0";
                        }
                        vfs_start()

                        function vfs_pause() {
                            document.getElementById('teaser_video').pause();
                        }

                        function vfs_play() {
                            document.getElementById('teaser_video').play();
                        }
                    </script>
                </div>
            </div>
            <hr>
            <p>
                Learning a good representation for space-time correspondence is the key for various computer vision
                tasks, including tracking object bounding boxes and performing video object pixel segmentation. To learn
                generalizable representation for correspondence in large-scale, a variety of self-supervised pretext
                tasks are proposed to explicitly perform object-level or patch-level similarity learning. Instead of
                following the previous literature, we propose to learn correspondence using Video Frame-level Similarity
                (VFS) learning, i.e, simply learning from comparing video frames. Our work is inspired by the recent
                success in image-level contrastive learning and similarity learning for visual recognition. Our
                hypothesis is that if the representation is good for recognition, it requires the convolutional features
                to find correspondence between similar objects or parts. Our experiments show surprising results that
                VFS surpasses state-of-the-art self-supervised approaches for both OTB visual object tracking and DAVIS
                video object segmentation. We perform detailed analysis on what matters in VFS and reveals new
                properties on image and frame level similarity learning.
            </p>
        </div>

        <div class="section">
            <h2>Oral Presentation</h2>
            <hr>
            <div class="vcontainer">
                <iframe class='video' src="https://www.youtube.com/embed/n-J8UCVEM1Y"
                    title="YouTube video player" frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen></iframe>
            </div>

        </div>

        <div class="section">
            <h2>Fine-grained Correspondence</h2>
            <p style="text-align: center;">
                Fine-grained correspondence is evaluated on res<sub>4</sub> feature map without fine-tuning.
            </p>
            <hr>
            <h4>DAVIS-2017 Video Object Segmentation</h4>
            <div class="row align-items-center">
                <div class="col-sm-6">
                    <img src="fig/dog.gif" style="width:100%">
                </div>
                <div class="col-sm-6">
                    <img src="fig/paragliding.gif" style="width:100%">
                </div>
            </div>
            <br>
            <div class="row align-items-center">
                <div class="col-sm-6">
                    <img src="fig/soapbox.gif" style="width:100%">
                </div>
                <div class="col-sm-6">
                    <img src="fig/kite-surf.gif" style="width:100%">
                </div>
            </div>
            <br>
        </div>
        <div class="section">
            <h2>Object-level Correspondence</h2>
            <p style="text-align: center;">
                Object-level correspondence is evaluated on res<sub>5</sub> feature map with fine-tuning.
            </p>
            <hr>
            <h4>OTB-100 Visual Object Tracking</h4>
            <div class="row align-items-center">
                <div class="col-sm-4">
                    <img src="fig/couple.gif" style="width:100%">
                </div>
                <div class="col-sm-4">
                    <img src="fig/mountainbike.gif" style="width:100%">
                </div>
                <div class="col-sm-4">
                    <img src="fig/davis3.gif" style="width:100%">
                </div>
            </div>
            <br>
            <div class="row align-items-center">
                <div class="col-sm-4">
                    <img src="fig/crossing.gif" style="width:100%">
                </div>
                <div class="col-sm-4">
                    <img src="fig/deer.gif" style="width:100%">
                </div>
                <div class="col-sm-4">
                    <img src="fig/jogging.gif" style="width:100%">
                </div>
            </div>

            <div class="section">
                <h2>More Fine-grained Correspondence</h2>
                <p style="text-align: center;">
                    Fine-grained correspondence is evaluated on res<sub>4</sub> feature map without fine-tuning.
                </p>
                <hr>
                <h4>VIP Human Part Segmentation</h4>
                <div class="row align-items-center">
                    <div class="col-sm-6">
                        <img src="fig/video37.gif" style="width:100%">
                    </div>
                    <div class="col-sm-6">
                        <img src="fig/video154.gif" style="width:100%">
                    </div>
                </div>
                <br>
                <div class="row align-items-center">
                    <div class="col-sm-6">
                        <img src="fig/video208.gif" style="width:100%">
                    </div>
                    <div class="col-sm-6">
                        <img src="fig/video297.gif" style="width:100%">
                    </div>
                </div>

                <br>
                <h4>JHMDB Human Pose Tracking</h4>
                <div class="row align-items-center">
                    <div class="col-sm-4">
                        <img src="fig/pullup.gif" style="width:100%">
                    </div>
                    <div class="col-sm-4">
                        <img src="fig/throw.gif" style="width:100%">
                    </div>
                    <div class="col-sm-4">
                        <img src="fig/sit.gif" style="width:100%">
                    </div>
                </div>
                <br>
                <div class="row align-items-center">
                    <div class="col-sm-4">
                        <img src="fig/kick.gif" style="width:100%">
                    </div>
                    <div class="col-sm-4">
                        <img src="fig/brush-hair.gif" style="width:100%">
                    </div>
                    <div class="col-sm-4">
                        <img src="fig/push.gif" style="width:100%">
                    </div>
                </div>
                <br>
            </div>

        </div>

        <div class="section">
            <h2>More results</h2>
            <hr>
            <div class="vcontainer">
                <iframe class='video' src="https://www.youtube.com/embed/H6cwwdf1p4I" frameborder="0"
                    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen></iframe>
            </div>
        </div>

        <div class="section">
            <h2>Paper</h2>
            <hr>
            <div>
                <div class="list-group">
                    <a href="https://arxiv.org/pdf/2103.17263" class="light-group-item">
                        <img src="fig/paper_thumbnail.jpg" style="width: 100%;" alt="">
                    </a>
                </div>
            </div>
        </div>

        <div class="section">
            <h2>BibTeX</h2>
            <hr>
            <div class="bibtexsection">
                <!-- @article{xu2021rethinking,
                    title={Rethinking Self-Supervised Correspondence Learning: 
                           A Video Frame-level Similarity Perspective},
                    author={Xu, Jiarui and Wang, Xiaolong},
                    journal={arXiv preprint arXiv:2103.17263},
                    year={2021}
                } -->
                <pre><code>
@inproceedings{xu2021rethinking,
    author    = {Xu, Jiarui and Wang, Xiaolong},
    title     = {Rethinking Self-Supervised Correspondence Learning: A Video Frame-Level Similarity Perspective},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {10075-10085}
}
                </code></pre>
            </div>
        </div>

        <hr>

        <footer>
            <p><span style="color: #AAAAAA">Acknowledgment: website template from <a
                        href="https://vsitzmann.github.io/siren/">SIREN</a></span></p>
        </footer>

        <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
            integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous">
        </script>
        <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
            integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous">
        </script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
            integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous">
        </script>

</body>

</html>